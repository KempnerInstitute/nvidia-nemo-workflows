#!/bin/bash
#SBATCH --job-name="gpt-meg"     # a name for your job
#SBATCH --partition=             # <---- partition to which job should be submitted
#SBATCH --account=               # <---- account to which job should be charged
#SBATCH --nodes=2                # node count
#SBATCH --ntasks-per-node=1      # total number of tasks across all nodes
#SBATCH --gpus-per-node=4        # Number of GPUs per node (4 per node)
#SBATCH --cpus-per-task=24
#SBATCH --mem=0
#SBATCH --time=02:35:00          # total run time limit (HH:MM:SS)
#SBATCH --output %x_%N_%j.out    # Output file
#SBATCH --error %x_%N_%j.out     # Error file

export GPUS_NODE=$SLURM_GPUS_PER_NODE
export NNODES=$SLURM_NNODES

WORLD_SIZE=$(($GPUS_NODE*$NNODES))
world_size=$(($GPUS_NODE*$NNODES))
export TP_SIZE=4
export PP_SIZE=2



src_pth="/n/holylfs06/LABS/kempner_shared/Everyone/common_envs/miniconda3/envs/mega_ml"
data_pth="/n/holylfs06/LABS/kempner_shared/Everyone/common_envs/miniconda3/envs/mega_ml/Megatron-LM/data"

env | grep -i python

export CUDA_DEVICE_MAX_CONNECTIONS=1
#export HYDRA_FULL_ERROR=1

nodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )
nodes_array=($nodes)
head_node=${nodes_array[0]}
head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-address)

for head_port in {20000..30000}; do ! nc -z localhost ${head_port} && break; done
echo $head_port

export MASTER_ADDR=$head_node_ip
export MASTER_PORT=$head_port
echo "MASTER_ADDR MASTER_PORT WORLD_SIZE"
echo $MASTER_ADDR $MASTER_PORT $WORLD_SIZE

#DISTRIBUTED_ARGS="--nnodes $NNODES --nproc-per-node $GPUS_NODE --master_addr $head_node_ip --master_port $head_port"
DISTRIBUTED_ARGS="--nnodes $NNODES --nproc-per-node $GPUS_NODE --rdzv_id $RANDOM --rdzv_backend c10d --rdzv_endpoint $head_node_ip:$head_port"

CHECKPOINT_PATH=./model_checkpoint
VOCAB_FILE=$data_pth/gpt2-vocab.json
MERGE_FILE=$data_pth/gpt2-merges.txt
DATA_PATH=$data_pth/codeparrot_content_document


TENSORBOARD_ARGS="--tensorboard-dir ./experiments/tensorboard"

GPT_ARGS="--num-layers 12
--hidden-size 768
--num-attention-heads 12
--seq-length 1024
--max-position-embeddings 1024
--micro-batch-size 12
--global-batch-size 12
--lr 0.0005
--train-iters 150000
--lr-decay-iters 150000
--lr-decay-style cosine
--lr-warmup-iters 2000
--weight-decay .1
--adam-beta2 .999
--fp16
--log-interval 10
--save-interval 2000
--eval-interval 200
--eval-iters 10
"

export CMD="torchrun $DISTRIBUTED_ARGS \
        /opt/megatron-lm/pretrain_gpt.py \
        --tensor-model-parallel-size $TP_SIZE \
        --pipeline-model-parallel-size $PP_SIZE  \
        $GPT_ARGS \
        --vocab-file $VOCAB_FILE \
        --merge-file $MERGE_FILE \
        --save $CHECKPOINT_PATH \
        --load $CHECKPOINT_PATH \
        --data-path $DATA_PATH \
        $TENSORBOARD_ARGS
     "
echo $CMD


echo "=================== Launching Job ================="
container_file="/n/holylfs06/LABS/kempner_shared/Everyone/containers/mlperf_benchmarking/nemo-25.02.rc0.simg"
srun -l singularity run --nv $container_file $CMD

echo "=================== Finished Job ================="
