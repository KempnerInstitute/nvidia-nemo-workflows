#!/bin/bash
#SBATCH --job-name="n1-meg"     # a name for your job
#SBATCH --partition=kempner_h100
#SBATCH --account=kempner_dev
#SBATCH --nodes=8                         # node count
#SBATCH --ntasks-per-node=4      # total number of tasks across all nodes
#SBATCH --time=00:35:00                           # total run time limit (HH:MM:SS)
#SBATCH --gpus-per-node=4                      # Number of GPUs per node (4 per node)
#SBATCH --cpus-per-task=24
#SBATCH --mem=64GB
#SBATCH --output %x_%N_%j.out           # Output file
#SBATCH --error %x_%N_%j.out             # Error file


export GPUS_NODE=$SLURM_NTASKS_PER_NODE
export NNODES=$SLURM_NNODES
NODE_RANK=0
WORLD_SIZE=$(($GPUS_NODE*$NNODES))
world_size=$(($GPUS_NODE*$NNODES))
export TP_SIZE=4
export PP_SIZE=8


data_pth="/n/holylfs06/LABS/kempner_shared/Everyone/workflow/nemo_pretrain_data/"


export CUDA_DEVICE_MAX_CONNECTIONS=1
export HYDRA_FULL_ERROR=1

nodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )
nodes_array=($nodes)
head_node=${nodes_array[0]}
head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-address)

for head_port in {20000..30000}; do ! nc -z localhost ${myport} && break; done
echo $head_port

export MASTER_ADDR=$head_node_ip
export MASTER_PORT=$head_port
echo "MASTER_ADDR MASTER_PORT WORLD_SIZE"
echo $MASTER_ADDR $MASTER_PORT $WORLD_SIZE

DISTRIBUTED_ARGS="--nproc_per_node $GPUS_NODE --nnodes $NNODES  --master_addr $head_node_ip --master_port $head_port"

CHECKPOINT_PATH=./model_checkpoint
VOCAB_FILE=$data_pth/gpt2-vocab.json
MERGE_FILE=$data_pth/gpt2-merges.txt
DATA_PATH=$data_pth/codeparrot_content_document


TENSORBOARD_ARGS="--tensorboard-dir ./experiments/tensorboard"

export CMD="
python /opt/NeMo/examples/nlp/language_modeling/megatron_gpt_pretraining.py \
    --config-path=/opt/NeMo/examples/nlp/language_modeling/conf \
    --config-name=megatron_gpt_config.yaml \
    trainer.devices=4 \
    trainer.num_nodes=8 \
    trainer.max_epochs=10 \
    trainer.max_steps=3000 \
    trainer.val_check_interval=300 \
    trainer.log_every_n_steps=50 \
    trainer.limit_val_batches=50 \
    trainer.limit_test_batches=50 \
    trainer.accumulate_grad_batches=1 \
    trainer.precision=bf16 \
    model.micro_batch_size=2 \
    model.global_batch_size=4 \
    model.tensor_model_parallel_size=$TP_SIZE \
    model.pipeline_model_parallel_size=$PP_SIZE \
    model.max_position_embeddings=1024 \
    model.encoder_seq_length=1024 \
    model.hidden_size=768 \
    model.ffn_hidden_size=3072 \
    model.num_layers=12 \
    model.num_attention_heads=12 \
    model.init_method_std=0.021 \
    model.hidden_dropout=0.1 \
    model.layernorm_epsilon=1e-5 \
    model.tokenizer.vocab_file=$VOCAB_FILE \
    model.tokenizer.merge_file=$MERGE_FILE \
    model.data.seq_length=1024 \
    model.data.num_workers=2 \
    model.data.data_prefix=[1.0,$DATA_PATH] \
    model.optim.name=fused_adam \
    model.optim.lr=6e-4 \
    model.optim.betas=[0.9,0.95] \
    model.optim.weight_decay=0.1 \
    model.optim.sched.name=CosineAnnealing \
    model.optim.sched.warmup_steps=750 \
    model.optim.sched.constant_steps=80000 \
    model.optim.sched.min_lr=6e-5 \
    exp_manager.resume_if_exists=True \
    exp_manager.resume_ignore_no_checkpoint=True \
    exp_manager.create_checkpoint_callback=True \
    exp_manager.checkpoint_callback_params.monitor=val_loss \
    exp_manager.checkpoint_callback_params.save_top_k=3 \
    exp_manager.checkpoint_callback_params.mode=min \
    exp_manager.checkpoint_callback_params.always_save_nemo=False
"

echo $CMD

echo "=================== Launching JoB ================="
container_file="/n/netscratch/kempner_dev/bdesinghu/container_images/nemo-25.02.rc0.simg"
srun -l singularity run --nv $container_file $CMD

echo "=================== Finished JoB ================="

